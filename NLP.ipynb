{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMkcvJLQOj6zo2Knx6LNsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Emmanuelprime/Emmanuelprime/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l7WT5Rzl2K18"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import json\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaring variable\n"
      ],
      "metadata": {
        "id": "xCBSdSHH5ALB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 10000\n",
        "feature_dimension = 40\n",
        "sentence_length = 50\n",
        "sentences =[]\n",
        "labels =[]\n"
      ],
      "metadata": {
        "id": "C-Tn9S-d5I5C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the dataset and reading the dataset"
      ],
      "metadata": {
        "id": "OuvQzLfd5xOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sca.json') as f:\n",
        "  sentences_from_data = json.load(f)\n",
        "  for items in sentences_from_data:\n",
        "    sentences.append(items['headline'])\n",
        "    labels.append(items['is_sarcastic'])\n"
      ],
      "metadata": {
        "id": "wuwx9QJI535o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of the text\n"
      ],
      "metadata": {
        "id": "Zk0wt7-j9afI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import pad_sequence\n",
        "ps = PorterStemmer()\n",
        "final_result = []\n",
        "for i in range(0,len(sentences)):\n",
        "  review = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "  review = review.lower()\n",
        "  #review = review.split()\n",
        "  #review = [ps.stem(word)for word in review if not word in stopwords.words('english')]\n",
        "  #review = ' '.join(review)\n",
        "  final_result.append(review)\n",
        "\n",
        "one_hot_rep = [one_hot(words,vocabulary_size)for words in final_result]\n",
        "sequenced_data = pad_sequences(one_hot_rep,padding ='post',maxlen = sentence_length)"
      ],
      "metadata": {
        "id": "NdYTuzm_9e7w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating train and test data"
      ],
      "metadata": {
        "id": "zmlcMBRjGbq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array(sequenced_data)\n",
        "Y = np.array(labels)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "-EBicppxGhd6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "XLHtMHRhCGyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocabulary_size,feature_dimension,input_length=sentence_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n",
        "    tf.keras.layers.Dense(64,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation ='sigmoid')\n",
        "])\n",
        "\n",
        "model2 =tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocabulary_size,feature_dimension,input_length=sentence_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(64,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(1, activation='relu')\n",
        "])"
      ],
      "metadata": {
        "id": "kfMnATq7CJwi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compiling the model"
      ],
      "metadata": {
        "id": "FkmI-d7fFmXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "model2.compile(optimizer = 'adam',loss ='binary_crossentropy',metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "5ASCx9XWFtLy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit the model"
      ],
      "metadata": {
        "id": "qSQjrNUAGWXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist1 = model1.fit(x_train,y_train,epochs =10,validation_data=(x_test,y_test),verbose=0)\n",
        "hist2 = model2.fit(x_train,y_train,epochs = 10,validation_data=(x_test,y_test),verbose = 0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7SlbfZdbGZiS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hist1 = pd.DataFrame(hist1.history)\n",
        "df_hist2 = pd.DataFrame(hist2.history)\n",
        "epochs =10\n",
        "\n",
        "print(df_hist1)\n",
        "print(df_hist2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PrGb22PIYgs",
        "outputId": "6742d6bb-9600-445e-a246-a6ec2cf2c590"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       loss  accuracy  val_loss  val_accuracy\n",
            "0  0.419652  0.795058  0.369967      0.834893\n",
            "1  0.253230  0.897693  0.382698      0.838637\n",
            "2  0.166522  0.939720  0.477796      0.829277\n",
            "3  0.113294  0.960547  0.550705      0.824598\n",
            "4  0.071028  0.977021  0.639090      0.813179\n",
            "5  0.047280  0.984462  0.776581      0.812617\n",
            "6  0.028856  0.990031  0.922197      0.812430\n",
            "7  0.021730  0.992418  1.057928      0.809247\n",
            "8  0.013583  0.995320  1.317217      0.806252\n",
            "9  0.010577  0.996537  1.385911      0.807001\n",
            "       loss  accuracy  val_loss  val_accuracy\n",
            "0  0.605434  0.726073  0.469468      0.827031\n",
            "1  0.416265  0.853746  0.481892      0.839199\n",
            "2  0.378497  0.875649  0.494404      0.832273\n",
            "3  0.645588  0.861188  0.576851      0.819543\n",
            "4  0.320354  0.892685  0.589275      0.827031\n",
            "5  0.284323  0.908972  0.834987      0.824410\n",
            "6  0.376858  0.891094  0.874399      0.823662\n",
            "7  1.030740  0.876773  6.465372      0.566080\n",
            "8  4.470323  0.643469  2.594527      0.716773\n",
            "9  0.855093  0.823326  0.860989      0.784350\n"
          ]
        }
      ]
    }
  ]
}